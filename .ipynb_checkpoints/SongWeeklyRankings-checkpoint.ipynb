{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping, pickle imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import string\n",
    "from functools import reduce\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KEYS\n",
    "SONG_TITLE_KEY = \"chart-element__information__song text--truncate color--primary\"\n",
    "SONG_ARTIST_KEY = \"chart-element__information__artist text--truncate color--secondary\"\n",
    "SONG_ELEMENT_KEY = \"chart-list__element display--flex\"\n",
    "RANK_ELEMENT_KEY = \"chart-element__rank__number\"\n",
    "urlBase = \"https://www.billboard.com/charts/billboard-200\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "songWeeklyRankColumns = ['Date', 'Title', 'Artist', 'Rank']\n",
    "songWeeklyRanks = pd.DataFrame(columns = songWeeklyRankColumns)\n",
    "\n",
    "#getSongs takes in a url address. \n",
    "#goes to specific url address, and parses through each element \n",
    "#such as song element to get the song name, song artist, and the song's rank\n",
    "def getSongs(url, date, df):\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    for element in soup.find_all(class_ = SONG_ELEMENT_KEY):\n",
    "        songName = element.find(class_ = SONG_TITLE_KEY).text #not unique\n",
    "        songArtist = element.find(class_ = SONG_ARTIST_KEY).text #not unique \n",
    "        rank = element.find(class_ = RANK_ELEMENT_KEY).text #not unique\n",
    "        df = df.append({'Date':date, 'Title':songName, 'Artist':songArtist, 'Rank':rank}, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "#pageIterator takes in url address, start date and end date. \n",
    "#iterates through each week from start date through end date.\n",
    "#calls a helper method, getSongs by passing in the url for the current week.\n",
    "def pageIterator(url, startDate, endDate, df):\n",
    "    current = datetime.fromisoformat(startDate)\n",
    "    end = datetime.fromisoformat(endDate)\n",
    "    \n",
    "    while current <= end:\n",
    "        #print(url+current.strftime('%Y-%m-%d'))\n",
    "        time.sleep(5) #add delay to prevent billboard for thinking we are a bot\n",
    "        df = getSongs(url+current.strftime('%Y-%m-%d'), current.strftime('%Y-%m-%d'), df)\n",
    "        #print(df.shape)\n",
    "        current += timedelta(weeks = 1)\n",
    "    return df\n",
    "    \n",
    "        \n",
    "songWeeklyRanks = pageIterator(\"https://www.billboard.com/charts/billboard-200/\", \"2020-01-01\", \"2021-01-01\", songWeeklyRanks)\n",
    "songWeeklyRanks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# songWeeklyRanks.to_pickle('songsWeeklyRanks.pkl')\n",
    "# test = pd.read_pickle('songsWeeklyRanks.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
